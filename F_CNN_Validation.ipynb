{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gmPXmaUsiQBI",
   "metadata": {
    "id": "gmPXmaUsiQBI"
   },
   "source": [
    "# Validation of Faster RCNN ResNet50\n",
    "\n",
    "\n",
    "This code performs object detection using a pre-trained Faster R-CNN ResNet-50 model trained on the COCO dataset. first the mode is sets up the model for evaluation, and defines functions for calculating Intersection over Union (IoU), average precision (AP), mean Average Precision (mAP), parsing predictions and XML annotations. Additionally, it loads images and corresponding XML annotations, sorts bounding boxes, calculates mAP for each class, and prints relevant information including bounding boxes and classes. Finally, it calculates and prints the mAP value and frames per second (fps) metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ec948b",
   "metadata": {
    "id": "b5ec948b"
   },
   "outputs": [],
   "source": [
    "#!pip install torch torchvision\n",
    "#!pip install opencv-python\n",
    "#!pip install pycocotools\n",
    "#!pip install torch opencv-python numpy Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbbb2290",
   "metadata": {
    "id": "dbbb2290"
   },
   "outputs": [],
   "source": [
    "# @title importing packages\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bd2fcd",
   "metadata": {
    "id": "81bd2fcd"
   },
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'aeroplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'sheep', 'horse', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "# Categories to be replaced with 'N/A'\n",
    "categories_to_replace = [ 'airplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                         'cow', 'dining table', 'dog', 'horse', 'motorcycle', 'person', 'potted plant',\n",
    "                         'sheep',  'train', 'tv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "WNXH6O7YC_LM",
   "metadata": {
    "id": "WNXH6O7YC_LM"
   },
   "outputs": [],
   "source": [
    "# @title Download or load model if True or False respectively\n",
    "# Define the computation device.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model  = fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1', weights_backbone=None).to(device)\n",
    "# Set the model to evaluation mode\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809daa2d",
   "metadata": {
    "id": "809daa2d"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "total_elapsed_time=[]\n",
    "def get_model(image_path):\n",
    "   '''\n",
    "    Functionality: Perform object detection on an image using a pre-trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path (str): Path to the input image file.\n",
    "\n",
    "    Returns:\n",
    "    - boxes (numpy.ndarray): Array of predicted bounding boxes for detected objects.\n",
    "    - pred_classes (list): List of predicted class names for detected objects.\n",
    "    '''\n",
    "   transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "  ])\n",
    "   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Read the image.\n",
    "   image = Image.open(image_path).convert('RGB')\n",
    "    # Create a BGR copy of the image for annotation.\n",
    "   image_bgr = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "   image = transform(image).to(device)\n",
    "   image = image.unsqueeze(0)\n",
    "   with torch.no_grad():\n",
    "    start_time = time.time()  # Record the start time\n",
    "    outputs = model(image)\n",
    "    end_time = time.time()  # Record the end time\n",
    "    elapsed_time = end_time - start_time\n",
    "    total_elapsed_time .append(elapsed_time)\n",
    "    print(f\"Time taken for prediction: {elapsed_time:.4f} seconds\")\n",
    "    # Get score for all the predicted objects.\n",
    "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "    # Get all the predicted bounding boxes.\n",
    "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
    "    # Get boxes above the threshold score.\n",
    "    # boxes = pred_bboxes[pred_scores >= 0.8].astype(np.int32)\n",
    "\n",
    "    pred_labels = outputs[0]['labels'].detach().cpu().numpy()\n",
    "    # Filter out boxes for the desired classes.\n",
    "    desired_indices = [i for i, label in enumerate(pred_labels) if COCO_INSTANCE_CATEGORY_NAMES [label] in categories_to_replace and pred_scores[i] >= 0.8]\n",
    "    boxes = pred_bboxes[desired_indices].astype(np.int32)\n",
    "    labels = pred_labels[desired_indices]\n",
    "    # Get all the predicted class names.\n",
    "    pred_classes = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in labels]\n",
    "    return boxes, pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4035167",
   "metadata": {
    "id": "f4035167"
   },
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "\n",
    "   '''\n",
    "    Functionality: Calculate the Intersection over Union (IoU) between two bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    - box1 (tuple): Tuple representing the coordinates of the first bounding box (x1, y1, x2, y2).\n",
    "    - box2 (tuple): Tuple representing the coordinates of the second bounding box (x1, y1, x2, y2).\n",
    "\n",
    "    Returns:\n",
    "    - iou (float): Intersection over Union (IoU) score between the two bounding boxes.\n",
    "    '''\n",
    "   x1 = max(box1[0], box2[0])\n",
    "   y1 = max(box1[1], box2[1])\n",
    "   x2 = min(box1[2], box2[2])\n",
    "   y2 = min(box1[3], box2[3])\n",
    "\n",
    "   intersection_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "   box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "   box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "   union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "   iou = intersection_area / float(union_area) if union_area > 0 else 0\n",
    "   return iou\n",
    "\n",
    "def calculate_average_precision(gt_boxes, pred_boxes, iou_threshold=0.5):\n",
    "\n",
    "   '''\n",
    "    Functionality: Calculate the average precision (AP) and recall for a set of ground truth and predicted bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    - gt_boxes (list): List of ground truth bounding boxes.\n",
    "    - pred_boxes (list): List of predicted bounding boxes.\n",
    "    - iou_threshold (float): IoU threshold for considering a detection as true positive.\n",
    "\n",
    "    Returns:\n",
    "    - precision (float): Precision score.\n",
    "    - recall (float): Recall score.\n",
    "    '''\n",
    "   tp = 0  # True Positives\n",
    "   fp = 0  # False Positives\n",
    "   fn = 0  # False Negatives\n",
    "\n",
    "   for i in range(min(len(gt_boxes), len(pred_boxes))):\n",
    "    iou = calculate_iou(gt_boxes, pred_boxes)\n",
    "    if iou >= iou_threshold:\n",
    "        tp += 1\n",
    "    else:\n",
    "       fp += 1\n",
    "\n",
    "    fn = len(gt_boxes) - tp\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "total = []\n",
    "\n",
    "def calculate_mAP(gt_boxes_list, pred_boxes_list, iou_threshold=0.5):\n",
    "\n",
    "  '''\n",
    "    Functionality: Calculate the mean Average Precision (mAP) for a set of ground truth and predicted bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    - gt_boxes_list (list): List of lists containing ground truth bounding boxes for each class.\n",
    "    - pred_boxes_list (list): List of lists containing predicted bounding boxes for each class.\n",
    "    - iou_threshold (float): IoU threshold for considering a detection as true positive.\n",
    "    '''\n",
    "  total_precision = 0.0\n",
    "  total_recall = 0.0\n",
    "  for class_idx, (gt_boxes, pred_boxes) in enumerate(zip(gt_boxes_list, pred_boxes_list)):\n",
    "        precision, recall = calculate_average_precision(gt_boxes, pred_boxes, iou_threshold)\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        print(f\"Class {class_idx + 1}: Precision={precision}, Recall={recall}\")\n",
    "        total.append(total_precision)\n",
    "\n",
    "def cal_mAP(ground_truth):\n",
    "   '''\n",
    "    Functionality: Calculate the mean Average Precision (mAP) for a set of ground truth bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    - ground_truth (list): List of ground truth bounding boxes.\n",
    "    '''\n",
    "   mAP =  sum(ground_truth)/ sum(total)\n",
    "   mAP = mAP  * 100\n",
    "   print(f\"mAP: {mAP}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c9198d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72c9198d",
    "outputId": "8e0b127e-9344-4ef4-e17d-be9faf17c621"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'voc challenge2007/VOC2007/JPEGImages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m all_pred_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Iterate over each image in the dataset\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m image_files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_file \u001b[38;5;129;01min\u001b[39;00m image_files:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Load the image\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'voc challenge2007/VOC2007/JPEGImages'"
     ]
    }
   ],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_dir = 'voc challenge2007/VOC2007/JPEGImages'\n",
    "annotation_dir = 'voc challenge2007/VOC2007/Annotations'\n",
    "\n",
    "def parse_prediction(prediction):\n",
    "  '''\n",
    "    Functionality: Parse predicted bounding boxes from a list of coordinates to a list of lists of integers.\n",
    "\n",
    "    Parameters:\n",
    "    - prediction (list): List of predicted bounding box coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - parsed_prediction (list): Parsed list of lists containing integer coordinates.\n",
    "    '''\n",
    "  parsed_prediction = [list(map(int, box)) for box in prediction]\n",
    "  return parsed_prediction\n",
    "\n",
    "# Function to parse XML annotations and extract ground truth bounding boxes\n",
    "def parse_annotation(xml_file):\n",
    "  '''\n",
    "    Functionality: Parse XML annotations to extract ground truth bounding boxes and object names.\n",
    "\n",
    "    Parameters:\n",
    "    - xml_file (str): Path to the XML annotation file.\n",
    "\n",
    "    Returns:\n",
    "    - gt_boxes (list): List of ground truth bounding boxes.\n",
    "    - gt_name (list): List of object names corresponding to the ground truth bounding boxes.\n",
    "    '''\n",
    "  tree = ET.parse(xml_file)\n",
    "  root = tree.getroot()\n",
    "  gt_boxes = []\n",
    "  gt_name = []\n",
    "  for obj in root.findall('object'):\n",
    "      name = obj.find('name').text\n",
    "      if name not in COCO_INSTANCE_CATEGORY_NAMES:\n",
    "          continue\n",
    "      bbox = obj.find('bndbox')\n",
    "      xmin = int(bbox.find('xmin').text)\n",
    "      ymin = int(bbox.find('ymin').text)\n",
    "      xmax = int(bbox.find('xmax').text)\n",
    "      ymax = int(bbox.find('ymax').text)\n",
    "      gt_boxes.append([xmin, ymin, xmax, ymax])\n",
    "      gt_name.append(name)\n",
    "\n",
    "\n",
    "  return gt_boxes, gt_name\n",
    "\n",
    "# image_path = 'VOC2007/JPEGImages/000004.jpg'\n",
    "\n",
    "all_pred_scores = []\n",
    "# Iterate over each image in the dataset\n",
    "image_files = os.listdir(image_dir)\n",
    "ground_truth = []\n",
    "for image_file in image_files:\n",
    "    # Load the image\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "    # image = Image.open(image_path).convert('RGB')\n",
    "    # Load the corresponding XML annotation\n",
    "    boxes, pred_classes = get_model(image_path)\n",
    "    annotation_file = os.path.splitext(image_file)[0] + '.xml'\n",
    "    annotation_path = os.path.join(annotation_dir, annotation_file)\n",
    "    print(f'Currently working on, annotation: {annotation_path} and image : {image_path}')\n",
    "    # Parse the XML file to get ground truth bounding boxes\n",
    "    gt_boxes, gt_name = parse_annotation(annotation_path)\n",
    "    ground_truth.append(len(gt_name))\n",
    "\n",
    "    def compare_function(lst):\n",
    "        return lst[0]\n",
    "\n",
    "    # Sort the first list based on the comparison function\n",
    "    gt_boxes_sorted = sorted(gt_boxes, key=compare_function)\n",
    "    pred_boxes_sorted = sorted(parse_prediction(boxes), key=compare_function)\n",
    "\n",
    "    print(f'The boxes are, Ground truth: {gt_boxes_sorted} and predicted : {pred_boxes_sorted}\\n')\n",
    "    print(f'The classes are, Ground truth: {gt_name} and predicted : {pred_classes}\\n')\n",
    "\n",
    "    iou_threshold_value = 0.5\n",
    "    calculate_mAP(gt_boxes_sorted, pred_boxes_sorted, iou_threshold_value)\n",
    "print(\"The Code has finished running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5670e9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5670e9c",
    "outputId": "ca563a91-8356-4575-e6dc-8990c9d5e811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 82.94290834613415%\n"
     ]
    }
   ],
   "source": [
    "cal_mAP(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc532770",
   "metadata": {
    "id": "dc532770"
   },
   "outputs": [],
   "source": [
    "def fps():\n",
    "   print('Total fps taken',sum(total_elapsed_time))\n",
    "   print('Average fps taken',sum(total_elapsed_time)/ len(total_elapsed_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46156354",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46156354",
    "outputId": "99cc8e79-9999-49b7-8c46-cb8f2a41619a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fps taken 483.2442395687103\n",
      "Average fps taken 0.09758567034909336\n"
     ]
    }
   ],
   "source": [
    "fps()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
