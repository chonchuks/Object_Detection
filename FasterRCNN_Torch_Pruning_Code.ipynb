{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7quO7NBf3o_"
   },
   "source": [
    "# Magnitude pruning of Faster RCNN ResNet50\n",
    "\n",
    "This code loads a Faster R-CNN ResNet-50 model, prunes it using magnitude-based pruning, saves the pruned model, and evaluates the pruned model. It also calculates and displays the size of the pruned model file. Detailed explanations for each variable and functionality are provided below.\n",
    "\n",
    "1.   List item\n",
    "2.   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHfbm2c3SbqZ",
    "outputId": "6b4ce93d-36b1-419a-c1bb-b517851cafaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_pruning in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.6)\n",
      "Requirement already satisfied: torch in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch_pruning) (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch_pruning) (1.23.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->torch_pruning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->torch_pruning) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->torch_pruning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->torch_pruning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->torch_pruning) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->torch_pruning) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch->torch_pruning) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\chuksonwubolu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch->torch_pruning) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# @title Torch-Pruning\n",
    "!pip install --upgrade torch_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xDZbKUVXTDVK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_pruning as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svGF6-tarYm8"
   },
   "source": [
    "### 1. Choose a model to prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OVNOjk3svKfP"
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qG4zfRnTvMVx",
    "outputId": "716926f8-5202-4ec4-c986-a79dfddba154"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the Faster R-CNN ResNet-50 model trained on COCO\n",
    "# base_model = fasterrcnn_resnet50_fpn(weights=None, weights_backbone=None)\n",
    "# base_model.load_state_dict(torch.load(\"/content/drive/Othercomputers/My Laptop/F_CNN/model/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\"))\n",
    "model  = fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1', weights_backbone=None).to(device)\n",
    "model1 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsxxIunJYvSz"
   },
   "source": [
    "### 2. Prepare a pruner\n",
    "\n",
    "Note: When we prune a model like ConvNext and ViT, torch-pruning will show a warning about unwrapped parameters. This warning is caused by `nn.Parameter` that does not belong to any standard layers such as `nn.Conv2d`, `nn.BatchNorm`. By default, Torch-Pruning will automatically prune the last non-singleton dim of these parameters. If you want to customize this behaviour, please provide an `unwrapped_parameters` list as the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iy82qvb38MKD",
    "outputId": "548705ae-72d5-4ef0-bb96-b7748d0fa724"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChuksOnwubolu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_pruning\\pruner\\algorithms\\metapruner.py:86: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\"ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\")\n",
      "C:\\Users\\ChuksOnwubolu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_pruning\\dependency.py:572: UserWarning: Maximum recursive depth reached!\n",
      "  warnings.warn(\"Maximum recursive depth reached!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Linear(in_features=512, out_features=182, bias=True), [0, 1, 2, 3, 29, 31, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 83, 87, 91, 92, 93, 94, 95, 97, 99, 101, 103, 104, 105, 106, 107, 116, 117, 118, 119, 120, 121, 122, 123, 129, 131, 136, 137, 138, 139, 140, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 172, 173, 175, 180, 181, 182, 183, 184, 208, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 235, 238, 239, 240, 241, 242, 264, 265, 266, 267, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 284, 285, 286, 287, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 326, 328, 330, 331, 332, 333, 334, 335, 340, 341, 342, 343, 344, 348, 349, 350, 351, 356, 357, 358, 359, 360, 361, 362, 363], <bound method LinearPruner.prune_out_channels of <torch_pruning.pruner.function.LinearPruner object at 0x0000026B98D466E0>>)\n",
      "\n",
      "(Linear(in_features=512, out_features=512, bias=True), [0, 3, 7, 8, 12, 13, 15, 16, 17, 18, 19, 25, 26, 29, 30, 31, 32, 34, 35, 37, 38, 39, 46, 48, 49, 53, 54, 58, 59, 60, 62, 63, 67, 69, 70, 72, 73, 75, 76, 77, 78, 80, 81, 84, 85, 86, 87, 89, 91, 92, 93, 99, 102, 103, 107, 108, 115, 116, 117, 118, 120, 123, 126, 129, 130, 135, 139, 144, 146, 149, 151, 152, 156, 157, 158, 159, 160, 161, 162, 163, 166, 167, 168, 170, 172, 174, 175, 176, 177, 178, 183, 185, 189, 190, 191, 192, 193, 194, 196, 197, 199, 200, 201, 206, 207, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 222, 223, 228, 229, 230, 231, 233, 239, 242, 244, 248, 250, 254, 256, 259, 260, 263, 265, 268, 281, 282, 283, 286, 287, 289, 292, 293, 297, 300, 301, 302, 304, 307, 310, 313, 315, 322, 323, 324, 326, 327, 329, 330, 332, 333, 336, 337, 338, 340, 341, 343, 344, 345, 346, 351, 352, 353, 355, 356, 357, 360, 365, 366, 373, 374, 377, 381, 384, 386, 387, 388, 389, 390, 394, 398, 401, 403, 404, 407, 411, 412, 414, 416, 417, 421, 422, 423, 424, 432, 433, 434, 435, 438, 441, 444, 445, 449, 450, 451, 453, 454, 455, 457, 459, 460, 462, 463, 466, 468, 469, 473, 475, 476, 477, 480, 484, 485, 487, 491, 492, 494, 496, 497, 499, 501, 502, 506, 508, 511, 515, 516, 517, 519, 522, 526, 528, 529, 530, 533, 535, 537, 538, 539, 540, 542, 543, 549, 550, 553, 554, 558, 559, 560, 561, 562, 564, 566, 568, 569, 570, 571, 573, 574, 576, 581, 582, 583, 584, 586, 587, 588, 589, 591, 595, 596, 597, 602, 603, 605, 608, 609, 612, 613, 614, 617, 618, 620, 623, 624, 625, 626, 628, 631, 632, 633, 637, 638, 639, 640, 642, 643, 648, 650, 651, 652, 653, 654, 657, 660, 661, 662, 665, 666, 667, 671, 674, 678, 681, 682, 683, 686, 689, 690, 692, 694, 695, 696, 697, 698, 700, 704, 705, 707, 711, 712, 713, 714, 715, 717, 718, 719, 721, 725, 726, 727, 728, 729, 734, 735, 737, 741, 742, 743, 744, 748, 749, 750, 751, 756, 758, 759, 761, 762, 763, 764, 765, 767, 768, 769, 773, 776, 778, 779, 781, 784, 785, 786, 787, 790, 792, 795, 797, 802, 803, 804, 805, 808, 809, 813, 815, 816, 817, 823, 825, 826, 829, 830, 831, 834, 835, 836, 838, 840, 846, 847, 848, 850, 851, 852, 853, 854, 856, 861, 863, 864, 865, 866, 867, 868, 869, 870, 873, 874, 876, 877, 878, 881, 884, 885, 886, 887, 889, 892, 896, 897, 900, 901, 903, 907, 908, 911, 912, 915, 916, 918, 921, 922, 924, 926, 927, 929, 930, 931, 932, 934, 935, 936, 938, 942, 945, 947, 948, 949, 953, 955, 960, 962, 965, 967, 969, 973, 975, 976, 978, 979, 981, 983, 987, 988, 989, 990, 991, 993, 994, 995, 998, 999, 1000, 1005, 1006, 1009, 1010, 1012, 1015, 1016, 1017, 1019], <bound method LinearPruner.prune_out_channels of <torch_pruning.pruner.function.LinearPruner object at 0x0000026B98D466E0>>)\n",
      "\n",
      "(Linear(in_features=6272, out_features=512, bias=True), [2, 4, 7, 8, 9, 13, 15, 16, 18, 20, 21, 22, 27, 29, 32, 33, 34, 36, 39, 44, 45, 49, 50, 52, 53, 60, 61, 63, 65, 66, 70, 75, 76, 77, 78, 84, 85, 87, 88, 90, 91, 93, 94, 100, 101, 102, 104, 109, 112, 114, 115, 116, 117, 118, 119, 121, 124, 126, 128, 131, 132, 133, 135, 139, 140, 141, 142, 145, 146, 148, 149, 152, 153, 158, 161, 162, 165, 166, 167, 168, 169, 172, 173, 175, 177, 178, 180, 182, 185, 186, 194, 198, 199, 202, 205, 207, 208, 209, 210, 212, 213, 215, 216, 218, 221, 224, 225, 227, 228, 229, 230, 232, 233, 234, 235, 237, 239, 240, 241, 243, 245, 250, 257, 258, 259, 261, 262, 263, 264, 267, 270, 272, 274, 275, 278, 279, 281, 283, 285, 286, 288, 290, 291, 292, 296, 299, 300, 301, 302, 305, 306, 307, 309, 311, 312, 314, 316, 317, 319, 320, 323, 324, 325, 326, 330, 333, 335, 337, 338, 340, 341, 342, 344, 348, 349, 357, 358, 361, 362, 365, 367, 369, 371, 373, 378, 379, 380, 381, 383, 384, 385, 388, 390, 391, 392, 393, 397, 398, 400, 402, 403, 404, 406, 408, 410, 415, 417, 418, 419, 421, 424, 425, 426, 427, 428, 429, 433, 434, 435, 436, 438, 440, 442, 444, 447, 448, 450, 458, 462, 463, 464, 466, 467, 468, 469, 471, 472, 473, 474, 478, 482, 484, 485, 493, 494, 495, 497, 498, 501, 502, 503, 506, 508, 509, 511, 513, 514, 515, 516, 517, 518, 520, 521, 522, 530, 531, 532, 533, 535, 541, 542, 543, 546, 547, 548, 549, 550, 551, 556, 558, 560, 562, 565, 566, 568, 570, 571, 575, 577, 578, 579, 582, 584, 585, 589, 594, 596, 597, 601, 602, 603, 605, 606, 609, 610, 611, 612, 613, 614, 616, 622, 624, 625, 626, 627, 628, 635, 636, 637, 640, 641, 642, 644, 646, 647, 649, 651, 653, 655, 657, 658, 661, 662, 664, 665, 666, 668, 669, 670, 676, 679, 680, 681, 683, 685, 686, 687, 689, 692, 693, 694, 695, 696, 705, 707, 708, 710, 714, 716, 717, 718, 719, 723, 730, 733, 734, 735, 738, 741, 751, 752, 753, 755, 758, 759, 761, 762, 764, 766, 767, 768, 769, 772, 773, 776, 777, 778, 779, 784, 788, 791, 792, 794, 795, 798, 801, 802, 803, 804, 805, 806, 808, 811, 812, 814, 815, 819, 820, 822, 823, 828, 835, 837, 838, 840, 841, 843, 844, 846, 847, 849, 850, 852, 855, 856, 859, 861, 862, 864, 868, 870, 871, 872, 873, 874, 876, 877, 878, 880, 881, 883, 884, 885, 888, 889, 890, 892, 895, 900, 901, 902, 910, 911, 913, 915, 916, 917, 918, 919, 922, 923, 924, 927, 928, 931, 932, 933, 934, 940, 943, 944, 945, 948, 950, 952, 958, 959, 961, 963, 965, 967, 968, 969, 970, 973, 974, 976, 977, 978, 979, 981, 983, 984, 985, 989, 990, 991, 994, 995, 996, 997, 1001, 1002, 1003, 1005, 1007, 1008, 1009, 1012, 1015, 1016, 1017], <bound method LinearPruner.prune_out_channels of <torch_pruning.pruner.function.LinearPruner object at 0x0000026B98D466E0>>)\n",
      "\n",
      "(Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), [0, 2, 3, 12, 23, 24, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 42, 43, 45, 49, 51, 52, 54, 55, 57, 58, 60, 62, 63, 66, 69, 70, 73, 78, 79, 80, 86, 90, 91, 94, 95, 96, 97, 98, 99, 101, 102, 104, 108, 112, 115, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 136, 137, 141, 142, 145, 146, 150, 151, 152, 156, 159, 160, 162, 163, 167, 169, 170, 172, 173, 174, 177, 178, 179, 180, 181, 182, 183, 184, 188, 191, 194, 195, 196, 197, 198, 199, 201, 202, 205, 206, 207, 208, 209, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 228, 234, 237, 239, 240, 241, 244, 246, 248, 249, 251], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1)), [0, 3, 4, 6, 8, 9, 11, 14, 15, 16, 17, 18, 19, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 37, 38, 43, 45, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 67, 69, 74, 77, 78, 79, 81, 82, 84, 85, 87, 88, 93, 94, 96, 97, 100, 104, 108, 109, 112, 115, 116, 118, 122, 123, 126, 127, 128, 129, 131, 136, 142, 144, 147, 148, 151, 153, 154, 155, 156, 162, 163, 166, 169, 172, 175, 178, 179, 186, 187, 188, 189, 190, 192, 193, 194, 195, 197, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 216, 218, 221, 222, 223, 224, 228, 229, 232, 234, 235, 236, 239, 241, 244, 245, 250, 255], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False), [0, 3, 7, 9, 10, 11, 13, 17, 18, 19, 20, 22, 23, 26, 28, 29, 31, 32, 33, 35, 42, 43, 44, 48, 50, 56, 57, 59, 61, 62, 72, 74, 75, 76, 78, 86, 87, 91, 93, 96, 98, 99, 102, 103, 105, 106, 107, 108, 111, 112, 115, 117, 118, 119, 120, 124, 125, 128, 131, 132, 133, 137, 139, 141, 144, 147, 148, 149, 151, 154, 156, 159, 161, 164, 165, 166, 169, 172, 175, 177, 179, 180, 181, 184, 185, 188, 190, 191, 192, 193, 194, 195, 196, 200, 203, 204, 208, 211, 214, 215, 216, 219, 224, 226, 227, 230, 231, 232, 235, 236, 241, 242, 244, 247, 248, 253, 255, 259, 260, 261, 263, 267, 269, 275, 276, 279, 282, 283, 286, 287, 291, 293, 297, 299, 302, 304, 308, 309, 312, 314, 315, 316, 318, 319, 323, 325, 328, 332, 333, 334, 335, 338, 340, 341, 342, 343, 344, 347, 351, 352, 354, 355, 356, 358, 360, 361, 364, 365, 366, 367, 369, 371, 374, 375, 378, 381, 382, 383, 384, 387, 388, 389, 390, 391, 392, 394, 395, 396, 397, 399, 400, 403, 405, 406, 408, 410, 411, 413, 414, 415, 417, 418, 423, 428, 432, 433, 437, 438, 439, 440, 443, 445, 446, 447, 448, 450, 453, 454, 455, 457, 458, 459, 461, 462, 463, 465, 466, 467, 470, 473, 475, 477, 481, 482, 485, 486, 489, 490, 491, 493, 494, 499, 500, 501, 502, 504, 505, 507, 509, 510, 511, 512, 514, 515, 517, 521, 522, 524, 525, 527, 529, 530, 533, 537, 539, 542, 544, 550, 551, 555, 560, 562, 563, 567, 573, 574, 575, 577, 578, 579, 580, 581, 582, 583, 584, 587, 590, 594, 598, 599, 602, 603, 604, 605, 606, 608, 611, 612, 618, 624, 625, 626, 627, 628, 629, 632, 635, 638, 640, 642, 648, 651, 652, 653, 658, 660, 665, 669, 671, 673, 675, 676, 678, 680, 684, 685, 688, 689, 691, 692, 693, 694, 696, 697, 698, 700, 701, 703, 704, 705, 706, 707, 708, 709, 710, 713, 715, 717, 718, 719, 724, 732, 733, 734, 736, 738, 739, 740, 743, 744, 747, 750, 751, 755, 764, 765, 767, 768, 771, 775, 776, 779, 787, 788, 792, 793, 800, 801, 802, 806, 810, 818, 819, 821, 822, 823, 825, 826, 827, 829, 831, 833, 835, 836, 839, 840, 841, 846, 847, 848, 850, 851, 852, 853, 856, 860, 861, 862, 863, 864, 866, 867, 868, 869, 870, 872, 873, 878, 879, 881, 883, 884, 886, 888, 889, 890, 891, 894, 895, 897, 900, 901, 903, 906, 910, 911, 912, 915, 917, 918, 920, 927, 928, 930, 931, 934, 935, 939, 940, 943, 945, 946, 949, 952, 956, 957, 961, 962, 964, 968, 970, 976, 978, 979, 982, 985, 986, 987, 988, 989, 991, 994, 995, 999, 1000, 1001, 1003, 1005, 1007, 1008, 1012, 1013, 1014, 1018, 1019, 1020, 1022, 1023, 1027, 1029, 1030, 1031, 1033, 1034, 1036, 1038, 1039, 1040, 1041, 1042, 1044, 1047, 1048, 1052, 1053, 1063, 1067, 1068, 1069, 1072, 1076, 1078, 1080, 1081, 1086, 1088, 1090, 1094, 1095, 1098, 1100, 1102, 1103, 1104, 1105, 1107, 1112, 1113, 1117, 1119, 1125, 1127, 1128, 1129, 1130, 1135, 1136, 1138, 1139, 1141, 1142, 1149, 1150, 1151, 1152, 1154, 1155, 1158, 1159, 1161, 1162, 1163, 1166, 1170, 1172, 1174, 1177, 1178, 1179, 1183, 1185, 1186, 1192, 1194, 1195, 1197, 1199, 1202, 1203, 1204, 1205, 1211, 1212, 1213, 1214, 1218, 1220, 1221, 1222, 1223, 1233, 1236, 1238, 1239, 1241, 1242, 1244, 1246, 1247, 1249, 1250, 1252, 1253, 1255, 1256, 1258, 1260, 1262, 1263, 1265, 1267, 1268, 1270, 1272, 1274, 1275, 1277, 1280, 1281, 1283, 1285, 1288, 1289, 1290, 1291, 1292, 1294, 1295, 1296, 1297, 1301, 1304, 1305, 1306, 1307, 1311, 1312, 1313, 1314, 1315, 1318, 1319, 1320, 1321, 1325, 1330, 1332, 1333, 1335, 1337, 1338, 1339, 1341, 1342, 1343, 1344, 1345, 1347, 1350, 1351, 1352, 1355, 1357, 1359, 1360, 1361, 1366, 1368, 1369, 1371, 1373, 1374, 1375, 1376, 1381, 1391, 1392, 1393, 1394, 1395, 1396, 1399, 1400, 1401, 1403, 1405, 1408, 1410, 1412, 1413, 1419, 1423, 1430, 1431, 1432, 1435, 1437, 1442, 1443, 1444, 1445, 1447, 1448, 1449, 1452, 1453, 1454, 1458, 1460, 1461, 1465, 1466, 1467, 1468, 1470, 1472, 1475, 1477, 1479, 1480, 1486, 1487, 1488, 1489, 1490, 1493, 1494, 1500, 1502, 1503, 1507, 1509, 1512, 1515, 1516, 1519, 1520, 1522, 1523, 1526, 1527, 1528, 1530, 1535, 1539, 1541, 1542, 1543, 1545, 1547, 1548, 1549, 1550, 1551, 1553, 1555, 1557, 1559, 1561, 1562, 1563, 1564, 1568, 1569, 1571, 1573, 1578, 1579, 1581, 1582, 1583, 1585, 1589, 1590, 1591, 1592, 1600, 1601, 1604, 1605, 1608, 1609, 1611, 1615, 1616, 1618, 1619, 1621, 1622, 1624, 1625, 1630, 1631, 1632, 1633, 1634, 1637, 1638, 1639, 1640, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1656, 1658, 1661, 1662, 1665, 1666, 1669, 1672, 1673, 1676, 1681, 1682, 1683, 1688, 1689, 1692, 1693, 1694, 1696, 1697, 1698, 1701, 1703, 1704, 1705, 1706, 1707, 1709, 1712, 1714, 1715, 1718, 1719, 1720, 1721, 1723, 1724, 1726, 1727, 1728, 1729, 1731, 1733, 1735, 1737, 1738, 1740, 1741, 1742, 1744, 1746, 1747, 1752, 1755, 1757, 1758, 1760, 1761, 1763, 1764, 1765, 1768, 1773, 1774, 1775, 1778, 1779, 1780, 1781, 1782, 1784, 1785, 1787, 1788, 1792, 1793, 1795, 1796, 1797, 1798, 1802, 1804, 1806, 1807, 1810, 1812, 1816, 1817, 1820, 1824, 1826, 1827, 1828, 1829, 1831, 1833, 1834, 1837, 1840, 1841, 1843, 1845, 1847, 1848, 1850, 1855, 1856, 1858, 1860, 1862, 1863, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1876, 1877, 1878, 1879, 1880, 1882, 1884, 1891, 1892, 1893, 1894, 1895, 1896, 1902, 1904, 1905, 1906, 1908, 1909, 1910, 1911, 1914, 1915, 1919, 1920, 1925, 1926, 1927, 1928, 1930, 1931, 1937, 1939, 1940, 1942, 1943, 1944, 1945, 1946, 1949, 1950, 1953, 1954, 1956, 1958, 1959, 1961, 1963, 1964, 1965, 1966, 1968, 1969, 1970, 1973, 1975, 1976, 1977, 1979, 1980, 1982, 1984, 1987, 1990, 1991, 1992, 1994, 1996, 1998, 1999, 2001, 2003, 2005, 2007, 2008, 2013, 2014, 2015, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2035, 2037, 2038, 2039, 2040, 2041, 2042, 2044, 2045, 2046, 2047], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False), [0, 3, 6, 8, 11, 14, 16, 18, 19, 22, 23, 26, 29, 30, 38, 39, 42, 46, 49, 50, 51, 52, 55, 56, 58, 60, 62, 64, 65, 66, 68, 70, 71, 72, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 89, 90, 91, 92, 94, 95, 96, 97, 102, 103, 108, 109, 111, 112, 113, 114, 119, 121, 123, 124, 125, 126, 127, 128, 130, 131, 134, 136, 138, 140, 141, 143, 144, 148, 149, 150, 153, 155, 156, 158, 160, 162, 163, 164, 166, 168, 169, 170, 173, 175, 177, 178, 179, 180, 181, 183, 185, 186, 188, 190, 195, 197, 198, 200, 202, 203, 204, 206, 207, 214, 215, 217, 220, 223, 228, 234, 237, 241, 242, 243, 244, 246, 247, 248, 251, 254, 255, 257, 260, 261, 262, 264, 266, 271, 275, 276, 277, 279, 282, 283, 284, 288, 289, 292, 295, 296, 297, 298, 301, 302, 304, 306, 307, 310, 312, 315, 317, 324, 325, 328, 330, 331, 332, 333, 335, 342, 344, 347, 352, 353, 355, 357, 358, 359, 361, 362, 363, 366, 368, 369, 370, 374, 375, 376, 378, 380, 381, 385, 388, 390, 391, 395, 396, 400, 402, 403, 404, 407, 408, 409, 411, 413, 414, 415, 420, 421, 423, 424, 425, 428, 429, 431, 433, 435, 436, 439, 442, 444, 445, 448, 450, 451, 455, 456, 458, 459, 460, 462, 464, 466, 467, 472, 475, 478, 484, 485, 486, 487, 488, 491, 492, 493, 494, 495, 496, 498, 501, 502, 505, 506, 507, 509, 510, 511, 514, 523, 524, 528, 532, 533, 535, 536, 541, 542, 544, 547, 548, 553, 555, 556, 557, 558, 560, 566, 567, 569, 571, 572, 573, 578, 580, 582, 588, 589, 590, 591, 592, 593, 595, 596, 599, 601, 602, 603, 604, 606, 611, 612, 617, 619, 622, 625, 626, 628, 629, 631, 633, 635, 637, 638, 639, 640, 644, 646, 648, 650, 651, 652, 653, 655, 656, 657, 660, 662, 663, 664, 680, 681, 682, 683, 685, 686, 688, 689, 690, 692, 696, 697, 700, 704, 705, 707, 709, 710, 711, 712, 716, 719, 723, 725, 726, 727, 728, 729, 730, 731, 732, 734, 735, 737, 738, 741, 743, 744, 745, 747, 748, 749, 753, 754, 757, 759, 760, 761, 762, 763, 764, 765, 766, 767, 770, 772, 773, 776, 780, 782, 784, 786, 787, 790, 792, 793, 794, 796, 800, 801, 803, 805, 807, 810, 812, 813, 814, 816, 817, 819, 821, 822, 824, 825, 826, 827, 830, 832, 833, 834, 835, 836, 838, 841, 843, 844, 846, 849, 851, 854, 856, 857, 858, 860, 863, 864, 865, 870, 871, 872, 873, 874, 875, 876, 877, 881, 883, 884, 887, 888, 889, 891, 893, 897, 899, 903, 904, 905, 906, 907, 909, 912, 916, 917, 918, 919, 920, 922, 924, 927, 928, 930, 934, 936, 941, 946, 950, 951, 952, 953, 955, 957, 959, 960, 961, 962, 963, 966, 971, 973, 976, 980, 981, 982, 986, 988, 990, 992, 995, 1000, 1002, 1003, 1007, 1011, 1012, 1018, 1019, 1020, 1021, 1022, 1023], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False), [1, 2, 4, 5, 8, 9, 11, 12, 13, 14, 16, 17, 18, 20, 21, 23, 25, 28, 32, 33, 34, 35, 43, 44, 49, 50, 51, 53, 55, 56, 59, 60, 61, 64, 67, 68, 72, 73, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 96, 101, 102, 103, 105, 109, 110, 112, 113, 114, 117, 119, 120, 121, 122, 127, 128, 129, 130, 131, 132, 133, 134, 140, 144, 147, 148, 149, 151, 153, 154, 157, 158, 159, 162, 163, 164, 165, 168, 169, 172, 173, 174, 176, 178, 181, 182, 183, 184, 189, 191, 196, 199, 200, 203, 204, 205, 206, 207, 210, 211, 213, 216, 220, 221, 222, 226, 227, 228, 229, 232, 233, 237, 239, 240, 242, 243, 244, 245, 246, 248, 249, 255, 256, 260, 261, 262, 263, 267, 269, 270, 271, 272, 273, 275, 277, 279, 280, 281, 283, 284, 285, 286, 288, 290, 291, 294, 297, 299, 300, 301, 305, 306, 307, 308, 311, 313, 319, 320, 322, 323, 324, 328, 330, 335, 338, 339, 344, 347, 348, 349, 350, 351, 355, 358, 361, 362, 364, 366, 369, 374, 376, 379, 382, 383, 386, 387, 388, 390, 392, 393, 397, 399, 400, 404, 405, 407, 408, 409, 412, 413, 416, 420, 422, 424, 426, 429, 430, 431, 432, 433, 434, 438, 440, 444, 446, 449, 451, 452, 453, 454, 457, 461, 462, 465, 466, 467, 470, 473, 474, 477, 480, 482, 488, 489, 491, 492, 493, 497, 500, 501, 505, 507, 508, 509, 511], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), [0, 5, 7, 8, 9, 11, 12, 14, 16, 18, 20, 22, 23, 24, 25, 29, 30, 34, 35, 38, 39, 43, 46, 47, 51, 53, 54, 55, 59, 60, 62, 65, 67, 71, 73, 74, 75, 77, 78, 79, 80, 81, 85, 89, 90, 92, 93, 94, 99, 102, 103, 105, 106, 108, 109, 110, 111, 112, 113, 116, 118, 125, 126, 127], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), [1, 2, 3, 7, 8, 9, 11, 12, 13, 14, 17, 19, 21, 22, 23, 25, 26, 27, 29, 31, 32, 35, 36, 41, 43, 46, 47, 48, 49, 51, 52, 53, 54, 55, 61, 62, 66, 67, 68, 69, 70, 74, 80, 83, 85, 87, 89, 90, 92, 97, 98, 99, 100, 101, 108, 109, 110, 111, 113, 117, 119, 120, 122, 123], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [0, 1, 5, 8, 9, 10, 13, 14, 17, 18, 20, 23, 26, 27, 28, 30, 32, 34, 38, 40, 42, 44, 46, 47, 48, 50, 54, 55, 56, 58, 59, 61, 62, 66, 67, 70, 71, 72, 76, 77, 81, 84, 85, 88, 90, 91, 93, 94, 96, 99, 100, 101, 107, 109, 111, 112, 113, 114, 117, 119, 120, 121, 122, 126], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), [1, 2, 3, 6, 8, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 30, 32, 34, 36, 40, 41, 42, 43, 44, 47, 48, 52, 53, 54, 55, 60, 63, 65, 66, 67, 68, 69, 71, 74, 78, 80, 82, 83, 84, 86, 87, 88, 90, 94, 95, 96, 99, 107, 108, 111, 114, 116, 117, 120, 121, 123, 125], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [0, 1, 2, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 28, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 49, 50, 51, 53, 58, 62, 63, 64, 68, 71, 73, 74, 75, 78, 81, 82, 83, 85, 86, 87, 92, 94, 95, 98, 99, 102, 104, 106, 108, 110, 115, 118, 119, 120, 123], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), [0, 1, 4, 5, 7, 12, 13, 17, 18, 22, 24, 25, 27, 28, 32, 33, 36, 37, 40, 42, 43, 47, 49, 50, 52, 53, 56, 57, 59, 60, 61, 64, 66, 71, 73, 74, 75, 77, 81, 82, 83, 86, 88, 92, 93, 95, 96, 97, 99, 101, 105, 109, 110, 112, 113, 114, 115, 116, 118, 121, 123, 125, 126, 127], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [0, 1, 2, 5, 8, 10, 11, 12, 14, 16, 21, 24, 25, 26, 27, 28, 29, 31, 32, 36, 37, 40, 41, 45, 47, 48, 54, 57, 58, 59, 62, 65, 66, 67, 70, 71, 72, 74, 75, 77, 79, 80, 81, 82, 83, 87, 88, 94, 95, 96, 97, 98, 99, 100, 101, 104, 108, 113, 117, 119, 120, 121, 122, 126], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), [3, 6, 8, 9, 12, 16, 19, 21, 23, 28, 30, 31, 32, 34, 36, 38, 39, 40, 41, 42, 46, 48, 49, 51, 53, 54, 59, 60, 61, 63, 64, 66, 70, 71, 75, 77, 78, 80, 81, 82, 83, 84, 85, 88, 89, 90, 91, 92, 99, 101, 103, 104, 106, 107, 108, 109, 111, 112, 116, 117, 121, 123, 125, 126], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), [0, 2, 3, 4, 5, 6, 12, 15, 16, 17, 19, 20, 21, 22, 23, 24, 28, 31, 32, 38, 40, 47, 48, 49, 50, 53, 54, 57, 58, 60, 62, 63, 65, 66, 69, 70, 72, 73, 74, 76, 77, 78, 79, 80, 87, 88, 89, 90, 91, 92, 98, 100, 103, 104, 106, 107, 111, 114, 116, 118, 119, 120, 123, 125, 129, 133, 137, 138, 140, 141, 145, 146, 147, 149, 151, 152, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 172, 173, 174, 177, 178, 180, 185, 187, 188, 189, 192, 194, 195, 196, 197, 199, 200, 202, 203, 207, 208, 212, 215, 216, 217, 219, 227, 230, 232, 236, 239, 240, 244, 246, 247, 248, 249, 251, 254], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), [0, 3, 7, 10, 11, 12, 14, 16, 17, 18, 19, 24, 26, 29, 30, 31, 32, 37, 39, 42, 44, 45, 46, 48, 49, 50, 52, 56, 57, 61, 63, 65, 68, 70, 72, 75, 76, 78, 81, 82, 83, 84, 87, 90, 92, 93, 94, 96, 98, 99, 100, 101, 103, 105, 106, 107, 109, 110, 112, 114, 118, 120, 121, 122, 124, 132, 135, 136, 137, 138, 139, 141, 143, 145, 146, 147, 148, 150, 151, 156, 157, 159, 160, 161, 163, 165, 167, 170, 171, 174, 178, 179, 180, 183, 184, 188, 190, 195, 196, 197, 199, 202, 206, 208, 209, 212, 214, 215, 217, 218, 221, 225, 226, 227, 230, 234, 236, 237, 240, 241, 244, 245, 248, 249, 250, 251, 253, 254], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [0, 3, 6, 8, 9, 11, 14, 16, 17, 19, 21, 22, 23, 24, 26, 28, 34, 36, 37, 38, 39, 40, 42, 45, 47, 48, 49, 53, 56, 57, 59, 60, 61, 64, 65, 66, 69, 72, 74, 82, 87, 88, 91, 93, 94, 95, 96, 97, 100, 102, 107, 108, 111, 112, 115, 121, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 144, 146, 147, 149, 151, 153, 155, 160, 162, 164, 165, 169, 174, 176, 178, 179, 181, 182, 184, 185, 188, 189, 190, 191, 192, 193, 195, 196, 198, 200, 201, 204, 205, 206, 209, 215, 216, 217, 220, 222, 228, 229, 231, 234, 235, 236, 237, 238, 239, 240, 241, 246, 248, 249, 250, 251, 254, 255], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), [1, 2, 5, 9, 11, 12, 14, 15, 17, 18, 20, 23, 27, 30, 31, 32, 34, 38, 41, 43, 44, 46, 47, 48, 49, 50, 51, 54, 55, 59, 63, 64, 66, 68, 70, 71, 72, 73, 75, 81, 82, 86, 87, 90, 91, 92, 93, 96, 97, 100, 101, 102, 104, 106, 108, 109, 110, 111, 112, 114, 115, 120, 121, 122, 123, 128, 132, 135, 136, 137, 138, 141, 142, 144, 146, 147, 148, 152, 154, 157, 158, 161, 162, 163, 164, 165, 171, 173, 176, 177, 179, 180, 181, 183, 184, 187, 188, 189, 193, 195, 199, 200, 203, 208, 209, 211, 213, 216, 217, 219, 220, 222, 223, 226, 227, 228, 229, 230, 231, 233, 234, 240, 244, 245, 248, 249, 250, 252], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [0, 1, 3, 7, 8, 10, 11, 13, 14, 15, 19, 21, 25, 26, 27, 31, 37, 40, 44, 45, 46, 47, 49, 50, 51, 56, 57, 58, 59, 60, 61, 62, 65, 67, 68, 69, 72, 73, 74, 76, 81, 84, 86, 88, 89, 96, 99, 100, 101, 102, 105, 108, 109, 111, 113, 115, 116, 119, 122, 123, 124, 125, 127, 128, 129, 133, 135, 136, 138, 143, 144, 146, 149, 151, 153, 154, 156, 157, 161, 163, 165, 166, 167, 169, 171, 172, 173, 176, 180, 182, 183, 184, 185, 186, 187, 190, 191, 192, 194, 195, 200, 204, 205, 211, 215, 216, 218, 222, 225, 226, 227, 230, 232, 233, 234, 235, 238, 240, 241, 243, 244, 246, 248, 249, 251, 252, 253, 255], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), [0, 1, 2, 3, 12, 13, 15, 20, 22, 23, 27, 28, 30, 31, 32, 33, 35, 37, 39, 42, 43, 48, 49, 50, 52, 54, 56, 57, 62, 63, 65, 66, 71, 73, 74, 76, 82, 83, 84, 87, 91, 93, 95, 96, 97, 102, 105, 107, 108, 112, 113, 117, 119, 122, 123, 125, 126, 128, 130, 132, 134, 137, 138, 142, 143, 145, 149, 151, 152, 155, 157, 159, 160, 162, 163, 164, 165, 171, 176, 177, 178, 180, 181, 183, 185, 188, 191, 193, 194, 195, 196, 197, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 215, 217, 219, 220, 221, 223, 224, 225, 229, 232, 233, 234, 235, 240, 242, 243, 246, 249, 250, 251, 252, 253, 254, 255], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [0, 2, 4, 5, 8, 9, 12, 13, 16, 18, 19, 24, 25, 26, 27, 28, 29, 32, 35, 37, 38, 40, 43, 44, 45, 46, 48, 50, 52, 54, 59, 63, 65, 67, 69, 70, 71, 75, 76, 77, 79, 81, 83, 84, 85, 89, 92, 93, 95, 97, 100, 101, 102, 103, 104, 106, 109, 111, 112, 114, 116, 117, 118, 119, 120, 123, 124, 125, 126, 129, 130, 131, 133, 134, 141, 142, 143, 146, 148, 149, 151, 155, 158, 161, 162, 164, 167, 169, 173, 174, 177, 178, 179, 180, 182, 184, 185, 189, 191, 194, 196, 197, 199, 203, 205, 206, 207, 211, 214, 216, 217, 219, 220, 222, 224, 225, 231, 232, 233, 235, 238, 239, 240, 243, 246, 247, 248, 255], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), [0, 4, 14, 15, 16, 18, 19, 22, 23, 24, 25, 26, 27, 29, 32, 34, 35, 36, 38, 39, 43, 47, 49, 51, 54, 56, 59, 62, 64, 67, 69, 71, 72, 74, 75, 76, 77, 79, 84, 87, 88, 90, 93, 98, 102, 104, 106, 107, 112, 113, 115, 116, 118, 119, 120, 122, 123, 124, 128, 129, 131, 133, 136, 139, 140, 141, 142, 143, 145, 146, 147, 149, 152, 153, 154, 158, 162, 163, 165, 167, 168, 169, 170, 172, 176, 181, 182, 183, 184, 188, 189, 192, 195, 196, 197, 200, 202, 203, 204, 206, 209, 210, 212, 213, 214, 215, 216, 219, 220, 221, 223, 224, 225, 226, 227, 230, 231, 233, 234, 235, 242, 243, 245, 246, 249, 252, 254, 255], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [2, 3, 5, 12, 13, 15, 17, 18, 19, 21, 23, 24, 28, 29, 30, 34, 35, 37, 38, 39, 41, 42, 43, 45, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 74, 76, 79, 80, 84, 87, 89, 94, 95, 100, 102, 103, 105, 107, 108, 110, 116, 117, 120, 123, 124, 129, 130, 132, 136, 137, 139, 140, 144, 146, 149, 152, 153, 155, 157, 158, 159, 160, 164, 165, 166, 170, 172, 174, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 190, 192, 198, 200, 203, 205, 206, 207, 209, 210, 212, 213, 216, 217, 218, 219, 220, 221, 223, 225, 230, 232, 233, 235, 236, 237, 239, 240, 241, 245, 254], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), [5, 10, 12, 14, 15, 16, 18, 20, 21, 23, 26, 27, 28, 31, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 59, 62, 65, 69, 72, 73, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 92, 93, 95, 96, 98, 99, 100, 102, 103, 105, 106, 107, 108, 109, 111, 113, 115, 117, 119, 122, 125, 126, 127, 130, 131, 132, 133, 139, 142, 144, 145, 149, 151, 152, 153, 155, 158, 160, 161, 162, 163, 164, 166, 169, 170, 172, 175, 177, 179, 181, 187, 190, 191, 192, 194, 197, 198, 201, 204, 207, 209, 213, 218, 220, 223, 226, 228, 235, 239, 241, 243, 246, 247, 253, 254, 255], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [3, 5, 9, 10, 12, 13, 17, 19, 21, 22, 26, 28, 29, 33, 35, 38, 41, 42, 45, 47, 48, 51, 52, 54, 58, 61, 63, 64, 65, 67, 69, 73, 74, 77, 78, 80, 82, 85, 86, 91, 93, 94, 95, 99, 100, 101, 103, 104, 107, 109, 111, 113, 115, 116, 119, 120, 121, 122, 123, 125, 127, 130, 131, 133, 136, 137, 139, 140, 142, 145, 146, 149, 151, 152, 153, 156, 158, 159, 160, 162, 163, 165, 168, 173, 176, 177, 178, 181, 182, 186, 187, 193, 194, 195, 196, 199, 205, 206, 209, 210, 211, 213, 214, 215, 216, 219, 220, 221, 222, 224, 225, 227, 232, 234, 235, 236, 239, 240, 241, 242, 243, 245, 247, 249, 250, 251, 252, 254], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), [4, 5, 7, 8, 12, 13, 17, 18, 20, 23, 25, 26, 28, 29, 30, 31, 34, 36, 37, 38, 42, 45, 48, 50, 51, 52, 54, 55, 57, 58, 59, 61, 64, 66, 67, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 89, 92, 93, 94, 96, 99, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 116, 117, 120, 124, 125, 126, 130, 133, 134, 137, 140, 141, 146, 149, 152, 153, 155, 159, 160, 162, 167, 168, 171, 174, 175, 176, 177, 179, 180, 181, 187, 188, 189, 190, 196, 197, 202, 203, 204, 206, 209, 210, 212, 213, 214, 215, 217, 225, 228, 229, 230, 232, 238, 246, 248, 250, 251, 252, 254, 255], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), [4, 5, 6, 11, 12, 13, 16, 18, 20, 22, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 41, 42, 43, 46, 47, 48, 49, 52, 54, 58, 59, 62, 64, 65, 66, 69, 70, 71, 74, 76, 77, 78, 80, 81, 85, 86, 88, 89, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 112, 116, 118, 119, 120, 121, 125, 129, 132, 133, 134, 137, 138, 139, 149, 150, 153, 154, 155, 157, 158, 160, 161, 162, 166, 167, 168, 172, 173, 176, 178, 179, 180, 187, 188, 189, 191, 192, 193, 196, 197, 200, 201, 203, 207, 208, 210, 212, 213, 214, 217, 219, 221, 225, 226, 228, 229, 235, 236, 240, 241, 242, 243, 244, 249, 250, 251, 252, 255, 256, 257, 258, 259, 261, 263, 264, 266, 267, 269, 270, 272, 274, 275, 276, 277, 281, 282, 283, 284, 285, 287, 288, 289, 292, 293, 294, 297, 299, 301, 303, 305, 306, 310, 312, 314, 315, 317, 318, 320, 329, 333, 334, 335, 345, 351, 352, 354, 355, 357, 359, 363, 364, 366, 370, 372, 373, 374, 375, 376, 377, 379, 381, 383, 385, 386, 389, 391, 394, 395, 396, 398, 399, 403, 404, 405, 408, 411, 413, 416, 417, 418, 419, 422, 423, 424, 425, 426, 429, 431, 432, 434, 436, 439, 440, 442, 448, 453, 455, 456, 458, 463, 464, 465, 466, 467, 473, 474, 475, 476, 478, 482, 484, 490, 491, 492, 493, 494, 495, 498, 499, 500, 504, 505, 507, 509, 510], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), [3, 5, 9, 10, 11, 15, 16, 17, 20, 22, 23, 26, 27, 28, 29, 30, 31, 34, 37, 38, 39, 41, 42, 46, 50, 51, 53, 57, 59, 61, 62, 63, 64, 69, 74, 77, 78, 79, 83, 84, 86, 87, 90, 91, 93, 94, 96, 97, 99, 101, 106, 107, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 129, 130, 131, 132, 133, 135, 137, 138, 139, 140, 143, 144, 150, 151, 152, 153, 155, 156, 158, 160, 161, 162, 163, 165, 167, 169, 173, 177, 178, 180, 183, 186, 188, 189, 190, 199, 203, 205, 207, 208, 210, 211, 212, 213, 216, 217, 219, 220, 221, 222, 224, 225, 226, 227, 234, 235, 236, 238, 239, 240, 244, 245, 247, 248, 249, 250, 252, 254, 256, 257, 260, 262, 268, 270, 271, 272, 274, 275, 277, 279, 282, 283, 285, 287, 288, 289, 291, 292, 298, 301, 303, 305, 306, 308, 309, 311, 314, 317, 320, 322, 323, 324, 325, 326, 329, 335, 336, 337, 338, 340, 344, 346, 347, 349, 351, 354, 355, 356, 358, 361, 362, 363, 364, 365, 366, 367, 369, 371, 372, 373, 374, 375, 381, 382, 385, 386, 387, 388, 390, 393, 395, 397, 400, 402, 407, 408, 409, 412, 413, 414, 418, 419, 420, 421, 422, 424, 425, 427, 432, 434, 436, 437, 439, 440, 443, 447, 451, 453, 456, 457, 459, 460, 465, 471, 473, 475, 477, 479, 483, 484, 486, 489, 491, 492, 495, 497, 498, 499, 505, 508, 509], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [0, 1, 4, 5, 7, 8, 10, 12, 13, 14, 16, 18, 20, 22, 26, 31, 33, 34, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 58, 60, 64, 69, 70, 71, 73, 74, 76, 77, 79, 81, 83, 84, 86, 90, 93, 94, 96, 97, 99, 100, 102, 104, 105, 109, 115, 118, 119, 121, 124, 125, 126, 127, 128, 129, 130, 133, 135, 136, 137, 140, 145, 152, 153, 154, 157, 159, 160, 162, 166, 168, 169, 170, 171, 172, 174, 175, 177, 180, 181, 184, 186, 191, 192, 193, 201, 202, 203, 204, 206, 207, 208, 209, 212, 216, 217, 218, 220, 221, 225, 226, 232, 233, 236, 237, 238, 240, 241, 242, 244, 245, 247, 249, 254, 255, 256, 259, 260, 262, 265, 266, 269, 272, 273, 277, 278, 279, 283, 285, 286, 287, 288, 289, 290, 295, 296, 302, 304, 307, 308, 310, 312, 313, 314, 322, 323, 324, 325, 327, 329, 334, 335, 336, 338, 344, 345, 347, 348, 349, 350, 351, 356, 357, 358, 359, 363, 364, 366, 369, 370, 371, 374, 375, 376, 378, 379, 381, 383, 384, 386, 387, 388, 390, 393, 394, 395, 397, 398, 400, 401, 402, 404, 406, 412, 414, 415, 416, 417, 419, 420, 421, 423, 426, 429, 430, 431, 434, 437, 439, 442, 444, 446, 447, 450, 452, 453, 454, 457, 458, 461, 465, 466, 467, 468, 472, 473, 474, 475, 484, 486, 488, 489, 491, 493, 494, 495, 498, 499, 501, 502, 504, 507, 510, 511], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), [0, 2, 4, 7, 8, 13, 14, 15, 16, 17, 21, 22, 25, 26, 27, 31, 33, 34, 35, 37, 38, 41, 42, 44, 47, 48, 49, 56, 58, 62, 63, 65, 66, 70, 71, 73, 75, 77, 80, 82, 83, 84, 90, 92, 95, 96, 105, 106, 109, 110, 112, 113, 115, 116, 117, 118, 122, 123, 126, 128, 129, 130, 131, 132, 134, 141, 143, 149, 151, 152, 153, 156, 158, 160, 166, 167, 170, 171, 173, 174, 175, 179, 181, 182, 185, 186, 187, 188, 191, 192, 194, 196, 197, 198, 199, 205, 206, 207, 208, 209, 210, 212, 214, 215, 217, 220, 223, 226, 228, 229, 234, 235, 236, 240, 242, 244, 245, 249, 254, 259, 262, 266, 267, 270, 271, 272, 275, 277, 278, 279, 280, 284, 285, 287, 288, 289, 290, 291, 293, 295, 297, 298, 303, 306, 307, 311, 313, 315, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 330, 331, 332, 333, 337, 340, 342, 343, 344, 345, 347, 348, 349, 351, 354, 355, 357, 358, 359, 360, 361, 362, 364, 366, 367, 369, 372, 373, 374, 376, 380, 381, 382, 383, 385, 389, 391, 398, 401, 402, 403, 404, 405, 409, 410, 411, 413, 415, 417, 418, 419, 420, 421, 422, 423, 424, 429, 430, 431, 433, 435, 436, 438, 439, 443, 444, 445, 448, 449, 450, 451, 453, 455, 456, 457, 458, 460, 461, 462, 467, 468, 473, 475, 476, 477, 479, 481, 484, 486, 488, 489, 490, 492, 493, 497, 500, 507, 509], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), [0, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 18, 23, 27, 30, 36, 37, 39, 40, 41, 44, 47, 48, 49, 52, 54, 61, 63, 69, 71, 72, 73, 75, 77, 78, 83, 87, 88, 89, 90, 93, 94, 95, 97, 98, 101, 103, 104, 105, 107, 110, 113, 114, 118, 119, 120, 121, 123, 124, 127, 129, 130, 131, 135, 138, 142, 143, 147, 148, 158, 159, 161, 163, 165, 167, 170, 172, 176, 177, 180, 181, 182, 184, 186, 188, 192, 196, 200, 201, 205, 206, 207, 209, 211, 215, 219, 221, 223, 225, 229, 232, 234, 236, 242, 244, 245, 248, 251, 252, 253, 259, 263, 264, 266, 267, 268, 269, 270, 273, 278, 280, 281, 285, 287, 289, 291, 295, 296, 297, 299, 301, 302, 303, 305, 306, 307, 308, 309, 310, 313, 315, 316, 317, 318, 321, 322, 327, 328, 331, 333, 336, 341, 342, 346, 347, 348, 349, 350, 351, 352, 354, 356, 357, 362, 363, 364, 365, 368, 369, 370, 371, 372, 373, 374, 376, 377, 379, 380, 382, 385, 386, 387, 389, 391, 392, 395, 399, 403, 404, 405, 406, 408, 409, 410, 411, 412, 413, 414, 416, 417, 420, 421, 422, 423, 424, 425, 427, 428, 432, 433, 435, 436, 437, 438, 439, 440, 441, 444, 445, 446, 447, 448, 451, 452, 458, 459, 460, 461, 462, 466, 467, 470, 472, 473, 475, 476, 477, 478, 479, 482, 483, 485, 486, 489, 492, 493, 497, 499, 501, 502, 503, 506, 507, 511], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False), [2, 3, 4, 14, 15, 17, 19, 20, 24, 25, 26, 28, 29, 31, 32, 37, 39, 40, 42, 44, 48, 49, 50, 51, 52, 55, 56, 57, 58, 61, 63, 64, 66, 67, 68, 70, 72, 74, 76, 77, 82, 83, 84, 85, 86, 88, 90, 91, 94, 95, 98, 104, 105, 107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 124, 125, 128, 130, 131, 132, 133, 134, 135, 137, 145, 146, 147, 151, 153, 155, 156, 158, 159, 160, 161, 164, 169, 170, 172, 180, 181, 185, 186, 187, 189, 190, 191, 194, 195, 200, 201, 203, 204, 207, 208, 209, 211, 212, 213, 216, 219, 224, 226, 227, 230, 231, 232, 233, 238, 239, 241, 243, 245, 247, 248, 249, 256, 257, 259, 260, 261, 265, 266, 269, 270, 273, 275, 277, 282, 288, 289, 292, 293, 294, 296, 297, 299, 301, 302, 304, 305, 306, 311, 313, 314, 317, 321, 324, 325, 327, 329, 331, 332, 334, 338, 343, 344, 347, 348, 349, 353, 354, 355, 356, 357, 358, 360, 362, 364, 367, 368, 369, 373, 375, 376, 377, 378, 379, 383, 384, 386, 388, 389, 390, 391, 394, 396, 397, 399, 401, 404, 405, 408, 415, 418, 424, 426, 427, 432, 433, 434, 439, 441, 442, 443, 445, 446, 447, 448, 450, 451, 454, 455, 456, 459, 460, 461, 463, 464, 465, 467, 468, 471, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 486, 488, 490, 491, 494, 495, 496, 500, 503, 506, 507, 511], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False), [0, 1, 3, 5, 8, 9, 10, 13, 16, 18, 19, 26, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 43, 44, 46, 50, 54, 55, 56, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 73, 74, 77, 78, 79, 80, 81, 82, 88, 90, 91, 92, 96, 98, 100, 103, 108, 109, 110, 111, 112, 113, 116, 119, 120, 122, 124, 125, 135, 138, 141, 144, 145, 146, 148, 150, 154, 156, 158, 159, 160, 162, 163, 165, 167, 171, 177, 181, 184, 186, 188, 189, 190, 191, 192, 193, 195, 197, 198, 200, 201, 203, 205, 208, 209, 214, 215, 223, 224, 226, 227, 228, 231, 233, 234, 235, 238, 239, 241, 242, 243, 244, 245, 250, 251, 252, 253, 254], <bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x0000026B98D46650>>)\n",
      "\n",
      "(Linear(in_features=512, out_features=45, bias=True), [7, 10, 11, 12, 13, 14, 23, 25, 26, 29, 30, 34, 36, 37, 39, 40, 41, 43, 45, 48, 49, 50, 53, 54, 55, 58, 59, 60, 66, 68, 69, 70, 71, 74, 75, 76, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90], <bound method LinearPruner.prune_out_channels of <torch_pruning.pruner.function.LinearPruner object at 0x0000026B98D466E0>>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Pruning using Magnitude Pruner\n",
    "\n",
    "\"\"\"Functionality: This code  applies magnitude-based pruning to the model.\n",
    "It then saves the pruned model's state dictionary and evaluates the pruned model.\n",
    "Finally, it calculates and displays the size of the pruned model file.\n",
    "\n",
    "Variables:\n",
    "- example_inputs: Example inputs for magnitude-based pruning.\n",
    "- imp: Importance metric for pruning.\n",
    "- ignored_layers: List of final classifier layers to be ignored during pruning.\n",
    "- pruner: MagnitudePruner object for pruning the model.\n",
    "- records: List to store pruning records for each layer.\n",
    "- g: Pruning group for each step in the pruning process.\n",
    "- dep: Dependency object containing layer information.\n",
    "- idxs: Indices of pruned channels in the layer.\n",
    "- layer: Layer being pruned.\n",
    "- pruning_fn: Pruning function applied to the layer.\n",
    "- file_name: Path to the saved pruned model file.\n",
    "- file_stats: Statistics of the saved model file.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "example_inputs = torch.randn(1, 3, 224, 224)\n",
    "imp = tp.importance.MagnitudeImportance(p=2)\n",
    "ignored_layers = []\n",
    "\n",
    "# DO NOT prune the final classifier!\n",
    "for m in model1.modules():\n",
    "    if isinstance(m, torch.nn.Linear) and m.out_features == 1000:\n",
    "        ignored_layers.append(m)\n",
    "\n",
    "pruner = tp.pruner.MagnitudePruner(\n",
    "    model1,\n",
    "    example_inputs,\n",
    "    importance=imp,\n",
    "    iterative_steps=1,\n",
    "    ch_sparsity=0.5, # remove 50% channels, ResNet18 = {64, 128, 256, 512} => ResNet18_Half = {32, 64, 128, 256}\n",
    "    ignored_layers=ignored_layers,\n",
    ")\n",
    "\n",
    "records = []\n",
    "for g in pruner.step(interactive=True):\n",
    "    dep, idxs = g[0]\n",
    "    layer = dep.layer\n",
    "    pruning_fn = dep.pruning_fn\n",
    "    records.append((layer, idxs, pruning_fn))\n",
    "    g.prune()\n",
    "\n",
    "for rec in records:\n",
    "    print(rec)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDUmL9ymW1sM",
    "outputId": "60b32f9e-1334-4cc6-83f8-a0dc4f920132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0-1): 2 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=6272, out_features=512, bias=True)\n",
       "      (fc7): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=512, out_features=45, bias=True)\n",
       "      (bbox_pred): Linear(in_features=512, out_features=182, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.zero_grad() # We don't want to store gradient information\n",
    "torch.save(model.state_dict(),'Mg_fasterrcnn_resnet50_pruned_model_2.pth')\n",
    "# model.load_state_dict(torch.load('/content/fasterrcnn_resnet50_pruned_model_2.pth'))\n",
    "model.load_state_dict(torch.load('Mg_fasterrcnn_resnet50_pruned_model_2.pth'), strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSYPWYWnRfaG",
    "outputId": "fd1bb88c-61f0-4caf-b398-c9ed798a3a89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.stat_result(st_mode=33206, st_ino=5348024558172762, st_dev=2318610902, st_nlink=2, st_uid=0, st_gid=0, st_size=44939950, st_atime=1707398929, st_mtime=1707398917, st_ctime=1707398917)\n",
      "File Size in Bytes is 44939950\n",
      "File Size in MegaBytes is 42.858076095581055\n"
     ]
    }
   ],
   "source": [
    "# get file size in python\n",
    "import os\n",
    "\n",
    "file_name = \"Mg_fasterrcnn_resnet50_pruned_model_2.pth\"\n",
    "\n",
    "file_stats = os.stat(file_name)\n",
    "\n",
    "print(file_stats)\n",
    "print(f'File Size in Bytes is {file_stats.st_size}')\n",
    "print(f'File Size in MegaBytes is {file_stats.st_size / (1024 * 1024)}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
